{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DynamicMazeQLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGZLw73kyesQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(2022)\n",
        "\n",
        "flag_list = [0, 1, 2, 3, 5, 6, 7, 8]\n",
        "#  [0, 1, 2\n",
        "#   3,    5\n",
        "#   6, 7, 8]\n",
        "\n",
        "time_list = [0, 1, 2]\n",
        "\n",
        "# the maze of size 201*201*2\n",
        "maze_cells = np.zeros((201, 201, 2), dtype=int)\n",
        "\n",
        "\n",
        "# load maze\n",
        "def load_maze():\n",
        "    file_path = \"COMP6247Maze20212022.npy\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise ValueError(\"Cannot find %s\" % file_path)\n",
        "\n",
        "    else:\n",
        "        global maze_cells\n",
        "        maze = np.load(file_path, allow_pickle=False, fix_imports=True)\n",
        "        maze_cells = np.zeros((maze.shape[0], maze.shape[1], 2), dtype=int)\n",
        "        for i in range(maze.shape[0]):\n",
        "            for j in range(maze.shape[1]):\n",
        "                maze_cells[i][j][0] = maze[i][j]\n",
        "                # load the maze, with 1 denoting an empty location and 0 denoting a wall\n",
        "                maze_cells[i][j][1] = 0\n",
        "                # initialized to 0 denoting no fire\n",
        "    return maze\n",
        "\n",
        "\n",
        "# get local 3*3 information centered at (x,y).\n",
        "def get_local_maze_information(x, y):\n",
        "    global maze_cells\n",
        "    random_location = random.choice(flag_list)\n",
        "    around = np.zeros((3, 3, 2), dtype=int)\n",
        "    for i in range(maze_cells.shape[0]):\n",
        "        for j in range(maze_cells.shape[1]):\n",
        "            if maze_cells[i][j][1] == 0:\n",
        "                pass\n",
        "            else:\n",
        "                maze_cells[i][j][1] = maze_cells[i][j][1] - 1  # decrement the fire time\n",
        "\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            if x - 1 + i < 0 or x - 1 + i >= maze_cells.shape[0] or y - 1 + j < 0 or y - 1 + j >= maze_cells.shape[1]:\n",
        "                around[i][j][0] = 0  # this cell is outside the maze, and we set it to a wall\n",
        "                around[i][j][1] = 0\n",
        "                continue\n",
        "            around[i][j][0] = maze_cells[x - 1 + i][y - 1 + j][0]\n",
        "            around[i][j][1] = maze_cells[x - 1 + i][y - 1 + j][1]\n",
        "            if i == random_location // 3 and j == random_location % 3:\n",
        "                if around[i][j][0] == 0:  # this cell is a wall\n",
        "                    continue\n",
        "                ran_time = random.choice(time_list)\n",
        "                around[i][j][1] = ran_time + around[i][j][1]\n",
        "                maze_cells[x - 1 + i][y - 1 + j][1] = around[i][j][1]\n",
        "    return around\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from enum import Enum, IntEnum\n",
        "\n",
        "\n",
        "class Action(IntEnum):\n",
        "    MOVE_UP = 0\n",
        "    MOVE_LEFT = 1\n",
        "    MOVE_RIGHT = 2\n",
        "    MOVE_DOWN = 3\n",
        "    STAY = 4\n",
        "\n",
        "class MOVEMENT(Enum):\n",
        "    MOVE_UP = (-1, 0)\n",
        "    MOVE_LEFT = (0, -1)\n",
        "    MOVE_RIGHT = (0, 1)\n",
        "    MOVE_DOWN = (1, 0)\n",
        "    STAY = (0, 0)\n",
        "\n",
        "\n",
        "class Environment():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.maze_size = 201\n",
        "        self.maze = np.ones((self.maze_size,self.maze_size,2))*-1\n",
        "        self.episode = 1\n",
        "        self.agent_curr_state = (1,1)\n",
        "        self.agent_next_state = (1,1)\n",
        "        self.win_reward = 1\n",
        "        self.penalty_move = -0.04 \n",
        "        self.visited_penalty =  -0.25\n",
        "        self.wall_penalty = -0.75\n",
        "        self.fire_penalty = -.8\n",
        "        \n",
        "\n",
        "        \n",
        "        self.goal_cell = (199,199)\n",
        "        self.reward_history = []\n",
        "        self.wall_count_history = []\n",
        "        self.visited_count_history = []\n",
        "        self.fire_count_history = []\n",
        "        self.total_reward = 0\n",
        "        self.qlearning = Qlearning(201, 4)\n",
        "\n",
        "        \n",
        "        self.max_step = 200000\n",
        "        self.step_counter = 0\n",
        "        self.wall_counter = 0\n",
        "        self.visited_counter = 0\n",
        "        self.stay_counter = 0\n",
        "        self.fire_counter = 0\n",
        "\n",
        "      \n",
        "        self.reset()\n",
        "\n",
        "    def check_game_status(self,action_idx,is_train):\n",
        "        row, col = self.agent_curr_state\n",
        "        nrow, ncol = self.agent_next_state\n",
        "\n",
        "        if (nrow, ncol) == self.goal_cell:\n",
        "            if(is_train):\n",
        "              self.qlearning.update_qtable(self.agent_curr_state,action_idx, self.win_reward, self.agent_next_state)\n",
        "            self.agent_curr_state = np.copy(self.agent_next_state)\n",
        "            self.plot()\n",
        "            self.episode += 1\n",
        "            self.reward_history.append(self.total_reward)\n",
        "            self.wall_count_history.append(self.wall_counter)\n",
        "            self.visited_count_history.append(self.visited_counter)\n",
        "            self.fire_count_history.append(self.fire_counter)\n",
        "            self.reset()\n",
        "\n",
        "        if self.step_counter >= self.max_step:\n",
        "            self.plot()\n",
        "            self.reward_history.append(self.total_reward)\n",
        "            self.wall_count_history.append(self.wall_counter)\n",
        "            self.visited_count_history.append(self.visited_counter)\n",
        "            self.fire_count_history.append(self.fire_counter)\n",
        "            self.episode += 1\n",
        "            self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.maze = np.copy(self.maze)\n",
        "        self.agent_curr_state = (1,1)\n",
        "        self.agent_next_state = (1,1)\n",
        "        self.visited = set()\n",
        "        self.visited.add(self.agent_curr_state)\n",
        "        self.total_reward = 0\n",
        "        self.step_counter = 0\n",
        "        self.wall_counter = 0\n",
        "        self.visited_counter = 0\n",
        "        self.fire = set()\n",
        "        self.stay_counter = 0\n",
        "    \n",
        "    def conduct_action(self, action):\n",
        "        row, col = self.agent_curr_state\n",
        "        new_r = row\n",
        "        new_c = col\n",
        "        v_reward = self.qlearning.learning_rate  * self.visited_penalty\n",
        "        visit_pen = [0,v_reward]\n",
        "        new_r,new_c = (row + MOVEMENT[Action(action).name].value[0], col \n",
        "                       + MOVEMENT[Action(action).name].value[1])\n",
        "        if action == 0:\n",
        "            visit_pen[0] = 3\n",
        "        elif action == 1:\n",
        "            visit_pen[0] = 2\n",
        "        elif action == 2:\n",
        "            visit_pen[0] = 1\n",
        "        elif action == 3:\n",
        "            visit_pen[0] = 0\n",
        "\n",
        "        if self.maze[new_r, new_c, 1] > 0:\n",
        "            self.fire.add((new_r,new_c))\n",
        "            reward = self.fire_penalty\n",
        "            self.fire_counter+=1\n",
        "            pass\n",
        "\n",
        "        elif self.maze[new_r, new_c, 0] == 0:\n",
        "            reward = self.wall_penalty\n",
        "            self.wall_counter+=1\n",
        "\n",
        "        elif (new_r, new_c) in self.visited:\n",
        "            row = new_r\n",
        "            col = new_c\n",
        "            reward = self.visited_penalty\n",
        "            self.visited_counter+=1\n",
        "\n",
        "        else:\n",
        "            row = new_r\n",
        "            col = new_c\n",
        "            reward = self.penalty_move\n",
        "\n",
        "        self.agent_next_state = (row, col)\n",
        "        return reward, action, visit_pen\n",
        "\n",
        "    \n",
        "    def populate_maze(self,around):\n",
        "      row, col = self.agent_curr_state\n",
        "\n",
        "      self.maze[row-1,col-1] = around[0, 0]\n",
        "      self.maze[row-1,col]   = around[0, 1]\n",
        "      self.maze[row-1,col+1] = around[0, 2]\n",
        "      self.maze[row,col-1]   = around[1, 0]\n",
        "      self.maze[row,col]     = around[1, 1]\n",
        "      self.maze[row,col+1]   = around[1, 2]\n",
        "      self.maze[row+1,col-1] = around[2, 0]\n",
        "      self.maze[row+1,col]   = around[2, 1]\n",
        "      self.maze[row+1,col+1] = around[2, 2]\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "    def action(self, is_train, render):\n",
        "\n",
        "        # Call get_local_maze_information() to observe the environment\n",
        "\n",
        "        row, col = self.agent_curr_state\n",
        "        around = get_local_maze_information(row,col)\n",
        "        self.populate_maze(around)\n",
        "        # self.map(get_local_maze_information(row,col))\n",
        "\n",
        "        reward, action_idx, visit_pen = self.conduct_action(self.qlearning.get_action((row,col)))\n",
        "      \n",
        "        nrow, ncol = self.agent_next_state\n",
        "        self.step_counter += 1\n",
        "        if(is_train==True):\n",
        "          self.qlearning.update_qtable((row,col),action_idx, reward, (nrow,ncol))\n",
        "          self.qlearning.update_one_value((nrow,ncol), visit_pen[0], visit_pen[1])\n",
        "          # print(\"Epoch: {0} Step: {1} Coordinate: {2} ---> {3} Action: {4}\".format(self.epoch,self.step,self.state,self.nstate,self.action_labels[action_idx]))\n",
        "          with open(\"Output.txt\", 'a') as f:\n",
        "              f.write(\"Episode: {0} Step: {1} Agent Location: {2} ---> {3} Action: {4} \\n\".format(self.episode,self.step_counter,self.agent_curr_state,self.agent_next_state,Action(action_idx).name))\n",
        "        else:\n",
        "          with open('output_eval.txt', 'a') as f:\n",
        "                    \n",
        "                    line_string = \"Step: \" + str(self.step_counter) + \", \"\n",
        "                    line_string += \"Position: (\" + str(nrow) + \", \" + str(ncol) + \"), \"\n",
        "                    line_string += \"Action: \" + Action(action_idx).name + \", \"\n",
        "                    line_string += \"Walls Hit: \" + str(self.wall_counter) + \", \"\n",
        "                    line_string += \"Visited States: \" + str(self.visited_counter) + \", \"\n",
        "                    line_string += \"Reward: \" + str(reward) + \"\\n\"\n",
        "                    f.write(line_string)\n",
        "                    line_string = \"Wall State         Fire State\\n\"\n",
        "                    f.write(line_string)\n",
        "                    for i in range(3):\n",
        "                            line_string = \"[\" + str(around[i, 0, 0]) + \"]\" + \"[\" + str(around[i, 1, 0]) + \"]\" + \"[\" + str(around[i, 2, 0]) + \"]          \"\n",
        "                            line_string += \"[\" + str(around[i, 0, 1]) + \"]\" + \"[\" + str(around[i, 1, 1]) + \"]\" + \"[\" + str(around[i, 2, 1]) + \"]\\n\"\n",
        "                            f.write(line_string)\n",
        "\n",
        "                    f.write('\\n')\n",
        "        self.total_reward+=reward\n",
        "        self.check_game_status(action_idx,is_train)\n",
        "\n",
        "        self.agent_curr_state = np.copy(self.agent_next_state)\n",
        "\n",
        "        if self.maze[row, col, 0] > 0.0 and ((row,col) not in self.visited):\n",
        "            self.visited.add((row, col))\n",
        "\n",
        "    def plot(self):\n",
        "            File=\"Pics\"\n",
        "            plt.figure(figsize=(10,10))\n",
        "            plt.grid('on')\n",
        "            nrows, ncols = self.maze.shape[0],self.maze.shape[1]\n",
        "            ax = plt.gca()\n",
        "            ax.tick_params(axis='both', which='both', top=False, bottom=False,left=False,right=False,grid_alpha=0,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "            canvas = np.copy(self.maze)\n",
        "\n",
        "            cmap = colors.ListedColormap(['black','white','tan', 'blue','gold','grey','crimson'])\n",
        "            bounds = [0,1,2,3,4,5,6,7]\n",
        "            norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "            for row,col in self.visited:\n",
        "                canvas[row,col,0] = 3\n",
        "            agent_row, agent_col = self.agent_curr_state\n",
        "            canvas[nrows-2, ncols-2, 0] = 4\n",
        "            canvas[agent_row, agent_col, 0] = 2\n",
        "\n",
        "            for row,col in self.fire:\n",
        "                canvas[row,col,0] = 6\n",
        "\n",
        "            plt.imshow(canvas[:,:,0], interpolation='none', cmap=cmap,norm=norm)\n",
        "            result = \"SUCCESS\" if  self.step_counter<self.max_step else \"FAILURE\"\n",
        "            plt.title(\"Episode: \"+str(self.episode)+\"  Steps: \"+str(self.step_counter)+\"  Status: \" + result +\"  Visited: \"+str(self.visited_counter)+\"    Wall: \"+str(self.wall_counter))\n",
        "            plt.savefig(File+\"/\"+str(self.episode)+\"_\"+str(self.step_counter))\n",
        "           \n",
        "\n",
        "class Qlearning:\n",
        "    def __init__(self, maze_size, num_actions, lr=1, discount_factor=.5, epsilon=.9):\n",
        "        self.q_table = np.zeros([maze_size, maze_size, num_actions])\n",
        "        self.learning_rate = lr\n",
        "        self.discount = discount_factor\n",
        "        self.epsilon = epsilon\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "    def update_qtable(self, state, action, reward, next_state):\n",
        "        x, y = state\n",
        "        ns_x, ns_y = next_state\n",
        "\n",
        "        self.q_table[x, y, action] = self.q_table[x, y, action] + self.learning_rate * (\n",
        "                reward + self.discount * self.q_table[ns_x, ns_y].max() - self.q_table[x, y, action])\n",
        "\n",
        "    def get_action(self, state):\n",
        "        q_values = self.q_table[state[0], state[1]]\n",
        "        if q_values.sum() != 0:\n",
        "            # print(np.argmax(q_values))\n",
        "            action = np.argmax(q_values)\n",
        "        else:\n",
        "            action = random.randint(0, self.num_actions - 1)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def load_q_table(self,file):\n",
        "      self.q_table = torch.load(file)\n",
        "      #print(self.q_table)\n",
        "\n",
        "    def save_q_table(self,file):\n",
        "      torch.save(self.q_table, file)\n",
        "\n",
        "    def update_one_value(self,state, action, q_value):\n",
        "        x, y = state\n",
        "        self.q_table[x, y, action] = self.q_table[x, y, action] + q_value\n"
      ],
      "metadata": {
        "id": "Wpo7VsCsyig4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from array import array\n",
        "from locale import normalize\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "load_maze()\n",
        "Maze=Environment()\n",
        "\n",
        "\n",
        "def train(num_episodes):\n",
        "  \n",
        "  ##### Training\n",
        "  while Maze.episode<num_episodes:\n",
        "\n",
        "      Maze.action(is_train=True, render=False)\n",
        "      \n",
        "\n",
        "  print( Maze.reward_history)\n",
        "  # Plot total rewards for each episode\n",
        "  fig_2 = plt.figure(10)\n",
        "  ax_2 = fig_2.gca()\n",
        "  ax_2.plot(np.arange(1, num_episodes), Maze.reward_history,  color='green')\n",
        "  ax_2.set_title('Total rewards plot', fontsize=14)\n",
        "  ax_2.set_xlabel('episode')\n",
        "  ax_2.set_ylabel('Total reward')\n",
        "  ax_2.grid()\n",
        "  ax_2.set_xticks(range(1, num_episodes, 1))\n",
        "  fig_2.savefig('total_rewards_plot.png')\n",
        "  plt.clf() \n",
        "\n",
        "  # Plot walls hit for each episode\n",
        "  print(Maze.wall_count_history)\n",
        "  fig_3 = plt.figure(10)\n",
        "  ax_3 = fig_3.gca()\n",
        "  ax_3.plot(np.arange(1, num_episodes), Maze.wall_count_history,  color='red')\n",
        "  ax_3.set_title('Total walls hit plot', fontsize=14)\n",
        "  ax_3.set_xlabel('episode')\n",
        "  ax_3.set_ylabel('Total Walls Hit')\n",
        "  ax_3.grid()\n",
        "  ax_3.set_xticks(range(1, num_episodes, 1))\n",
        "  fig_3.savefig('total_walls_hit_plot.png')\n",
        "  plt.clf() \n",
        "  \n",
        "  print(Maze.visited_count_history)\n",
        "\n",
        "  # Plot visited states for each episode\n",
        "  fig_4 = plt.figure(10)\n",
        "  ax_4 = fig_4.gca()\n",
        "  ax_4.plot(np.arange(1, num_episodes), Maze.visited_count_history,  color='orange')\n",
        "  ax_4.set_title('Total Visited States plot', fontsize=14)\n",
        "  ax_4.set_xlabel('episode')\n",
        "  ax_4.set_ylabel('Total Visited States')\n",
        "  ax_4.grid()\n",
        "  ax_4.set_xticks(range(1, num_episodes, 1))\n",
        "  fig_4.savefig('total_visited_states_plot.png')\n",
        "  plt.clf() \n",
        "\n",
        "\n",
        "  # Plot fire states for each episode\n",
        "  fig_4 = plt.figure(10)\n",
        "  ax_4 = fig_4.gca()\n",
        "  ax_4.plot(np.arange(1, num_episodes), Maze.fire_count_history,  color='red')\n",
        "  ax_4.set_title('Total Fire States plot', fontsize=14)\n",
        "  ax_4.set_xlabel('episode')\n",
        "  ax_4.set_ylabel('Total Fire States')\n",
        "  ax_4.grid()\n",
        "  ax_4.set_xticks(range(1, num_episodes, 1))\n",
        "  fig_4.savefig('total_fire_states_plot.png')\n",
        "  plt.clf() \n",
        "  \n",
        "  torch.save(Maze.qlearning.q_table, 'q_table.pt')\n",
        "\n",
        "def test(num_episodes):\n",
        "  if(os.path.exists('q_table.pt')):\n",
        "    Maze.qlearning.q_table = torch.load('q_table.pt')\n",
        "    #Maze.q_values = torch.load('q_table.pt')\n",
        "    # Evaluate\n",
        "    print(\"Evaluating Q Agent.\")\n",
        "    # Create .txt output file\n",
        "    f = open('output_eval.txt', 'w')\n",
        "    f.write('Dynamic maze solving algorithm - output file \\n')\n",
        "    f.close()\n",
        "    while Maze.episode<num_episodes:\n",
        "        Maze.action(is_train=False, render=False)\n",
        "   \n",
        "  \n",
        "\n",
        "train(6)\n",
        "##### Evaluation\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "32NvzPtVyt1K",
        "outputId": "312943af-0a83-4e6e-98ff-d61981a29173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-5c8f89b70c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;31m##### Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-122-5c8f89b70c25>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_episodes)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mMaze\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mMaze\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-121-d4d6cdea37a5>\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, is_train, render)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_curr_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0maround\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_local_maze_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_maze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# self.map(get_local_maze_information(row,col))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-ecb62fff8390>\u001b[0m in \u001b[0;36mget_local_maze_information\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaze_cells\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaze_cells\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmaze_cells\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visit_pen = [0,0]\n",
        "visit_pen[0] ="
      ],
      "metadata": {
        "id": "NW4yPKaw0y-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visit_pen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UelPkWYH9qgt",
        "outputId": "bab0b33a-a76e-402f-f7be-c0618bb393b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YOfj5C099rfs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}